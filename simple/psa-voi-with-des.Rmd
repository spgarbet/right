---
title: Probabilistic Sensitivity Analyses and Value of Information with Discrete Event
  Simulation
output:
  html_document: default
  html_notebook: default
bibliography: psa-voi-with-des.bib
---

This notebook is designed to explore probabilistic sensitivity analysis (PSA) and value of information (VOI) methods with a simple discrete event simulation (DES) model.  

# Description of Model

We begin with a simple DES model with the following characteristics:

1. A population of 40-year olds are at risk for an event (A) that happens at a 10% rate over a 5 year period.
2. All those who experience the event incur a cost of $10,000.
3. Among those who experience the event, there is a 5% case fatality rate.  
4. Among those who survive, they experience a 0.25 utility decrement for the remainder of their life. 
5. Among the surviors, there is a second event (B) that occurs with probability 50% over a 5 year period.
6. Event B has no case fatality but incurs a $25,000 cost and a 0.10 disutility for 1 year 
7. There is a new therapy available that reduces the rate of the first event by a relative risk of 0.85, however the therapy costs $8,000.

# Sample Size Calculations

We will utilize the methodology outlined in @ohagan_monte_2007 to estimate the correct sample size, as well as to perform the PSA via ANOVA methods.

## Notation adopted from @ohagan_monte_2007

[Note much of this is *word for word* so do not use it in a manucript.]

Let $\textbf{x}$ denote the vector of model parameters whose uncertainty we with to account for.  Let $y(\textbf{x})$ denote the "true" model output for input vector $\textbf{x}$.  

We never observe the true value $y(\textbf{x})$ but rather each iteration of the simulation model produces, for each simulated patient a value $z$ that is $y(\textbf{x})$ plus noise, and this noise has zero expectation. 

Let $\textbf{x}_i$ denote the $i$th sampled parameter set, and let $z_{ij}$ denote the output value for the $j$th individual patient in the model run using inputs $\textbf{x}_i$.

The subscript $i$ ranges from 1 to $N$, the number of parameter sets sampled in the PSA.  The subscript $j$ runs from 1 to $n$, the number of patients simulated in each model run.

We denote the mean output for run $i$ by $\bar z_i$ and the mean over all $Nn$ patients in all model runs by $\bar z$. 

Our goal in performing the PSA is to examine the probability distribution of $y(\textbf{X})$, and this distribution is what would be obtained if we were able to compute $y_i = y(\textbf{x}_i)$ for a large sample of parameter sets $\textbf{x}_i$. 

We are particularly interested in the mean and the variance of this distribution:

\[
\mu = E(y(\textbf{X}))
\]

\[
\sigma^2 = var(y(\textbf{X}))
\]

The variance term $\sigma^2$ refers to *second order uncertainty* in the model (i.e., uncertainty in the paramters) but first order uncertainty is also important. This arises due to variability among paitents in the population.  

Let $\tau^2(\textbf{x})$ be the parient-level variance for simulations of patients with paremters $\textbf{x}$ and let 

\[
\bar \tau^2 = E(\tau^2(\textbf{X}))
\]
be the mean value of $\tau^2(\textbf{x})$ averaged with respect to the uncertainty in X.  

In general the larger the patient-level variability the more patients we will need to sample in each run.  

Let $k$ denote the ratio of these two variances:

\[
k = \bar \tau^2 / \sigma^2
\]
so that $\bar \tau^2 = k \sigma^2$.


## Incremental Net Benefit

We define $\lambda$ as the willingness to pay coefficient, and define the **incremental net benefit** as

\[
z = \lambda \times \Delta e - \Delta c
\]
where $\Delta e$ is the patients increment in effectiveness between two competing strategies and $\Delta c$ is the increment in costs.  

Using this we can define $y$ as the population mean incremental net benefit and treatment 2 is cost-effective if $y>0$.  

Our goal in PSA is to quantify uncertainty in whether $y>0$.  




## Implementation
A key step is in knowing the ratio $k = \bar \tau^2 / \sigma^2$.  We do so by first obtaining a prior estimate of $k$. @ohagan_monte_2007 suggest that to do so, the model input value for the initial set of runs should not be chosen randomly; we want the input parameter sets to have broad coverage of the input space.  They suggest a small number $N$ of runs, on the order of 25-40, with inputs sets chosen to be spread broadly across the space of possible inputs, and a moderate to large value of $n$.  

Let $u$ denote the number of uncertain input parameters for the model.  Moreover, we want to use $p$ values for each input, and we can use these to construct a grid of combinations. 

A Latin Hypercube sampling technique can be used so that each level of each factor is used the same number of times.  



```{r, message=FALSE, warning=FALSE}
source("./main_file.R")
source("./costs_simple.R")
require(knitr)
require(msm)
  ## Look at summary statistics
  results <- patient.attributes <- NULL
```

Set the run parameters

```{r, message=FALSE, warning=FALSE,cache=FALSE}

inputs$vHorizon <- 90
inputs$vAge <- 40
inputs$vGender <- 1  # 1 = Female, 2= Male
inputs$vN <- 1000

for(strategy in c("Standard","Treat")) {
  inputs$vStrategy <- strategy
  cat("Running ", strategy, "\n")
  run <- exec.simulation(inputs)
  run$strategy <- strategy
  
  attributes <- arrange(get_mon_attributes(env),name,key,time) 
  attributes <- spread(attributes %>% group_by(name,key) %>% summarise(first = first(value)),key,first) %>% data.table()
  attributes$strategy = strategy 
  
  if(is.null(results)) { results <- run} else  {results <- rbind(results, run)}
  if(is.null(patient.attributes)) { patient.attributes <- attributes} else { patient.attributes <- rbind(patient.attributes,attributes) }
}

DT <- data.table(results)
summary <- DT[, .N, by = list(resource,strategy)]
summary %>% dcast(resource~strategy,value.var="N") %>% kable()

```

```{r, message=FALSE, warning=FALSE}
s1 <- cost.qaly(subset(results,strategy=="Standard"),inputs) %>% mutate(strategy="Standard")
s2 <- cost.qaly(subset(results,strategy=="Treat"),inputs) %>% mutate(strategy="Treat")
sum_costs <- rbind(s1,s2) %>% mutate(ICER = (lag(dCOST)-dCOST)/(lag(dQALY)-dQALY)) 
kable(sum_costs)
```


## Estimate the incremental net benefit. 

```{r}
lambda <- 100000 # Willingness to pay parameter
inb1 <- cost.qaly.i(subset(results,strategy=="Standard"),inputs) %>% mutate(strategy="Standard")
inb2 <- cost.qaly.i(subset(results,strategy=="Treat"),inputs) %>% mutate(strategy="Treat")
NMB <- inb1 %>% left_join(inb2,"name") %>% mutate(dQALY = dQALY.y - dQALY.x, dCOST = dCOST.y - dCOST.x, NMB = lambda * dQALY - dCOST ) 

NMB %>% summarise(mNMB = mean(NMB), vNMB = var(NMB)) %>% mutate( seNMB = sqrt(vNMB/inputs$vN)) %>% kable()

```


## Latin Hypercube Sampling for the PSA

We have several parameters we would like to examine in our probabilistic sensitivity analysis.  These parameters (and plausible ranges) have been highlighted in bold in the model description below.

1. A population of 40-year olds are at risk for an event (A) that happens at a **10% [8-12%]** rate over a 5 year period.
2. All those who experience the event incur a cost of $10,000.
3. Among those who experience the event, there is a **5% [2-7%]** case fatality rate.  
4. Among those who survive, they experience a **0.25 [0.2-0.3]** utility decrement for the remainder of their life. 
5. Among the surviors, there is a second event (B) that occurs with probability **50% [30-70]** over a 5 year period.
6. Event B has no case fatality but incurs a $25,000 cost and a **0.10 [0.7-0.13]** disutility for 1 year 
7. There is a new therapy available that reduces the rate of the first event by a relative risk of **0.85 [0.75-0.95]**, however the therapy costs $8,000.


## Latin Hypercube Sampling

We'll draw from the parameter space using a latin hypercube design.  The randomLHS function draws a uniform sample which can then be transformed into any distirbution using the quantile function.  

To execute the latin hypercube sampling, we'll first specfiy a list object which summarizes the type and parameters of each unknown parameter in the model. 

```{r}
pp <- list(
  vRiskA = list(
    type = "beta",
    parameter = "vRiskA",
    shape1 = 100,
    shape2 = 900
  ),
  vFatalA = list(
    type = "uniform",
    parameter = "vFatalA",
    min = 0.01,
    max = 0.09
  ),
  A_survive = list(
    type = "uniform",
    parameter = "A_survive",
    min = 0.20,
    max = 0.25
  ),
  vRiskB = list(
    type = "uniform",
    parameter = "vRiskB",
    min = 0.45,
    max = 0.55
  ),
  B = list(
    type = "uniform",
    parameter = "B",
    min = 0.07,
    max = 0.13
  ),
  vRR = list(
    type = "beta",
    parameter = "vRR",
    shape1 = 850,
    shape2 = 150
  )
)
```

We'll now draw a random hypercube sample based on the number of parameters listed in the list object.  Once we draw the uniform draws from the hypercube sample, we'll apply the specific quantile function for the model parameter to get its draw for that iteration of the model.


```{r, message=FALSE, warning=FALSE}
require(lhs)
require(tidyverse)
X <- randomLHS(10, length(pp))
colnames(X) = names(pp)

lhc.draws.transformed <- cbind.data.frame(lapply(pp,function(x) 
  {
    if (x[["type"]]=="beta")
    {
      qbeta(X[,x[["parameter"]]],shape1=x[["shape1"]],shape2=x[["shape2"]])
    } 
    else if (x[["type"]]=="uniform")
    {
      qunif(X[,x[["parameter"]]],min=x[["min"]],max=x[["max"]])
    }   
  }
))
lhc.draws.transformed %>% head()

```

